{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\n\nimport pandas as pd\ntrain_df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/train.csv\")\ntest_df = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/test.csv\")\nsub = pd.read_csv(\"/kaggle/input/kaggle-llm-science-exam/sample_submission.csv\")\n\n\n# Split the data into training and validation sets\ntrain_text = train_df['prompt']\ntrain_labels = train_df['answer']\nX_train, X_val, y_train, y_val = train_test_split(train_text, train_labels, test_size=0.1, random_state=42)\n\n# Vectorize the text data using TF-IDF\nvectorizer = TfidfVectorizer(lowercase=True, strip_accents='unicode', stop_words='english')\nX_train_vec = vectorizer.fit_transform(X_train)\nX_val_vec = vectorizer.transform(X_val)\n\n# Train a random forest classifier\nmodel = RandomForestClassifier(n_estimators=100, random_state=42)\nmodel.fit(X_train_vec, y_train)\n\n\n# Vectorize the test data using the same vectorizer\nX_test_vec = vectorizer.transform(test_df['prompt'])\n\n# Make predictions on the test data\npredictions = model.predict_proba(X_test_vec)\n\n# Get the three best choices for each prediction\nbest_choices = []\nfor prediction in predictions:\n    top_choices = prediction.argsort()[-3:][::-1]\n    best_choices.append([model.classes_[choice] for choice in top_choices])\n\n# Create a DataFrame with the predictions\npredictions_df = pd.DataFrame({'id': test_df['id'], 'prediction': best_choices})\n\n# Format predictions as per submission requirements\npredictions_df['prediction'] = predictions_df['prediction'].apply(lambda x: ' '.join(x))\n\n# Save the predictions to a submission file\npredictions_df.to_csv('submission.csv', index=False)\n\n# Evaluate the predictions using Mean Average Precision @ 3 (MAP@3)\ndef calculate_map3(true_labels, predicted_labels):\n    map3 = 0\n    for true, pred in zip(true_labels, predicted_labels):\n        relevant_labels = set(true.split())\n        precision = 0\n        num_predictions = 0\n        for i, label in enumerate(pred.split()):\n            if label in relevant_labels:\n                precision += 1\n                relevant_labels.remove(label)\n                num_predictions += 1\n            if num_predictions == 3:\n                break\n        map3 += precision / 3\n    map3 /= len(true_labels)\n    return map3\n\n# Example usage:\ntrue_labels = ['A B C', 'B', 'C A B']\npredicted_labels = ['A B C', 'A', 'B C']\nmap3_score = calculate_map3(true_labels, predicted_labels)\nprint(\"MAP@3 Score:\", map3_score)\nfrom sklearn.model_selection import cross_val_score\n\n\n\n# Perform cross-validation\nscores = cross_val_score(model, X_train_vec, y_train, cv=5, scoring='accuracy')\nprint(\"Cross-Validation Scores:\", scores)\nprint(\"Mean Cross-Validation Score:\", np.mean(scores))\n\n# Fit the model on the entire training data\nmodel.fit(X_train_vec, y_train)\n\n# Vectorize the test data using the same vectorizer\nX_test_vec = vectorizer.transform(test_df['prompt'])\n\n# Make predictions on the test data\npredictions = model.predict_proba(X_test_vec)\n\n# Get the three best choices for each prediction\nbest_choices = []\nfor prediction in predictions:\n    top_choices = prediction.argsort()[-3:][::-1]\n    best_choices.append([model.classes_[choice] for choice in top_choices])\n\n# Create a DataFrame with the predictions\npredictions_df = pd.DataFrame({'id': test_df['id'], 'prediction': best_choices})\n\n# Format predictions as per submission requirements\npredictions_df['prediction'] = predictions_df['prediction'].apply(lambda x: ' '.join(x))\n\n# Save the predictions to a submission file\npredictions_df.to_csv('submission.csv', index=False)\n\n# Evaluate the predictions using Mean Average Precision @ 3 (MAP@3)\nmap3_score = calculate_map3(y_val, predictions_df['prediction'])\nprint(\"MAP@3 Score:\", map3_score)","metadata":{"execution":{"iopub.status.busy":"2023-08-31T10:57:49.989664Z","iopub.execute_input":"2023-08-31T10:57:49.990064Z","iopub.status.idle":"2023-08-31T10:57:52.699688Z","shell.execute_reply.started":"2023-08-31T10:57:49.990032Z","shell.execute_reply":"2023-08-31T10:57:52.698631Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"},{"name":"stdout","text":"MAP@3 Score: 0.5555555555555555\nCross-Validation Scores: [0.25       0.19444444 0.30555556 0.19444444 0.22222222]\nMean Cross-Validation Score: 0.2333333333333333\nMAP@3 Score: 0.21666666666666665\n","output_type":"stream"}]}]}